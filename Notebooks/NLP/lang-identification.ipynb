{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rLLHK5ryE1H"
   },
   "source": [
    "# Homework 1: Language Identification\n",
    "11-411/11-611 Natural Language Processing (Fall 2025)\n",
    "\n",
    "- RELEASED: Thursday, September 11, 2025\n",
    "- DUE: Thursday, October 2, 2025 11:59 pm EDT\n",
    "\n",
    "**Submission**: Please upload this single file named `HW1.ipynb` to [gradescope](https://www.gradescope.com/courses/1039018). Ensure you do not rename the file prior to submission.\n",
    "\n",
    "\n",
    "In this assignment, you will build a language identification classifier that distinguishes between six languages:\n",
    "\n",
    "- [Hausa](https://en.wikipedia.org/wiki/Hausa_language)\n",
    "- [Indonesian](https://en.wikipedia.org/wiki/Indonesian_language)\n",
    "- [Manobo](https://en.wikipedia.org/wiki/Manobo_languages)\n",
    "- [Nahuatl](https://en.wikipedia.org/wiki/Nahuatl)\n",
    "- [Swahili](https://en.wikipedia.org/wiki/Swahili_language)\n",
    "- [Tagalog](https://en.wikipedia.org/wiki/Tagalog_language)\n",
    "\n",
    "Some languages can be distinguished easily, because they use different scripts. These six languages, however, use the same ([Latin](https://en.wikipedia.org/wiki/Latin_script)) script with minimal [diacritics](https://en.wikipedia.org/wiki/Diacritic) so it is difficult to hand-craft classifiers based on the presence or absence of particular characters. Indeed, unless you have linguistic training or familiarity with the languages, it is difficult to tell them apart.\n",
    "\n",
    "How can they be distinguished? A naïve approach is to use word counts as unigram features. However, the number of possible words in a large corpus of five languages is vast. It is essential to look at something smaller — characters.\n",
    "\n",
    "Even though the six languages use roughly the same characters, the relative frequencies of these characters vary greatly. Thus, using characters as features (unigram character models) is appealing (and fairly effective). It is also true that languages vary in their *phonotactics*, the way in which consonants and vowels combine in sequence. Thus, looking at character ngrams (for small values of $n$) is also appealing (and effective). Note, however, that as the value of $n$ increases, this approach runs into the same problem as the word unigram model (sparcity). In this scenario, the model is likely to overfit.\n",
    "\n",
    "Various kinds of classifiers can be used for this application. NB classifiers, for example, are quite effective. However, inference is slow and performance, given the same training set, is likely to be worse than other options. Simple logistic regression cannot be used because this is an n-way (multinomial) classification problem. Multinomial Logistic Regression (Softmax Regression) is a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLyf3G0tyE1J"
   },
   "source": [
    "## Requirements\n",
    "\n",
    "You will perform the following tasks:\n",
    "\n",
    "1. Implement a training loop for Multinomial Logistic Regression.\n",
    "2. Implement inference for Multinomal Logistic Regression\n",
    "3. Determine the optimal order of $n$ for ngrams for MNLR trained on the training set.\n",
    "4. Calculate and display a confusion matrix for a trigram model evaluated on the test set.\n",
    "5. Inspect the feature weights, and display the most predictive features for each language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrCw0790yE1J"
   },
   "source": [
    "## How to Use Jupyter Notebooks for Our Assignment\n",
    "Throughout our first assignment, we'll utilize Jupyter Notebooks to walk you through concepts, let you implement them, and also allow you to experiment on your own. By the end of this assignment, you'll not only understand word embeddings more deeply but will also become familiar with a powerful tool used extensively in the data science community.\n",
    "\n",
    "### Types of Cells:\n",
    "**Markdown Cells**: These cells (like the one you're reading now) are utilized to write text, frame explanations, embed images, or even formulate equations. They make our notebook more explanatory and structured.\n",
    "\n",
    "**Code Cells**: This is where the action happens. In these cells, you'll write and execute Python code. They will play a critical role in our exercises as you experiment with word embeddings.\n",
    "\n",
    "*Warning*: Refrain from rearranging, adding, or deleting any cells.\n",
    "\n",
    "### Runtime Volatility\n",
    "As you navigate and execute the cells within this Jupyter notebook, it's crucial to understand that the runtime environment is volatile. In simpler terms:\n",
    "\n",
    "*   If you restart the notebook or experience a disconnection, all your in-memory data and variables will be lost.\n",
    "*   While the code and markdown cells will remain, the outputs from code cells will need to be regenerated by rerunning them.\n",
    "\n",
    "Therefore, if you're working on a task over an extended period or with large datasets, remember to save your results and progress frequently to avoid potential data loss.\n",
    "\n",
    "\n",
    "### Running this Notebook on Google Colab\n",
    "Google Colab is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. To run this notebook on Colab:\n",
    "\n",
    "1.   Save a copy of this notebook on your **Google Drive**.\n",
    "2.   Open the notebook in Google Colab.\n",
    "3.   In Google Colab, you can execute each cell using the play button (or use the keyboard shortcuts mentioned above).\n",
    "\n",
    "**Tip**: Google Colab may automatically disconnect after a certain period of inactivity. Keep this in mind, especially when running longer tasks.\n",
    "\n",
    "**Note**: Google Colab provides free access to GPUs and TPUs, which might be useful for later assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZWqjeNuyE1K"
   },
   "source": [
    "## Important: Library Restrictions\n",
    "\n",
    "**You must implement multinomial logistic regression from scratch using only the provided imports.**\n",
    "\n",
    "You are **NOT allowed** to use:\n",
    "- PyTorch, TensorFlow, or any other deep learning frameworks\n",
    "- Scikit-learn or other machine learning libraries  \n",
    "- Any external optimization libraries\n",
    "\n",
    "You may only use the imported libraries: `csv`, `random`, `numpy`, and `collections.Counter`.\n",
    "\n",
    "## Imports\n",
    "Do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759511632378,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "L2x9fT-5yE1K"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import numpy.testing as testing\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKs9Yu7nyE1K"
   },
   "source": [
    "## Helper Functions\n",
    "### Understanding Data Structures\n",
    "\n",
    "Throughout this assignment, you'll work with these key data structures:\n",
    "\n",
    "1. **Raw observations**: `list[tuple[str, str]]` - List of (language_name, document_text) pairs\n",
    "2. **Processed observations**: `list[tuple[np.ndarray, np.ndarray]]` - List of (one_hot_label, feature_vector) pairs\n",
    "3. **Weight matrix W**: `np.ndarray` shape `[K, N]` where K=number of languages, N=number of features\n",
    "   - **Important**: Column 0 contains bias terms, so remember to prepend 1 to feature vectors\n",
    "4. **Feature map**: `dict[str, int]` - Maps n-gram strings to feature indices\n",
    "5. **Language map**: `dict[str, np.ndarray]` - Maps language names to one-hot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6KiQ1O7yE1K"
   },
   "source": [
    "### Metrics for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1759511632410,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "PXDTvSxGyE1L"
   },
   "outputs": [],
   "source": [
    "def precision(tp: int, fp: int) -> float:\n",
    "    \"\"\"Computes the precision, given true positives and false positives.\"\"\"\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "\n",
    "def recall(tp: int, fn: int) -> float:\n",
    "    \"\"\"Computes the recall, given the true positives and false negatives.\"\"\"\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "\n",
    "def f_measure(beta: float, tp: int, fp: int, fn: int) -> float:\n",
    "    \"\"\"Computes the F-measure for a given beta, true positives, false positives, and false negatives.\"\"\"\n",
    "    return (\n",
    "        (1 + beta**2)\n",
    "        * (precision(tp, fp) * recall(tp, fn))\n",
    "        / (beta**2 * precision(tp, fp) + recall(tp, fn))  # ← FIXED: + instead of *\n",
    "    )\n",
    "\n",
    "\n",
    "def f1(tp: int, fp: int, fn: int) -> float:\n",
    "    \"\"\"Computes the F1 measure for a given TP, FP, and FN.\"\"\"\n",
    "    return f_measure(1, tp, fp, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yM1mJJs4yE1L"
   },
   "source": [
    "### Micro-Averaged Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759511632426,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "LxugZlTPyE1L"
   },
   "outputs": [],
   "source": [
    "def micro_precision(tp: \"dict[str, int]\", fp: \"dict[str, int]\") -> float:\n",
    "    \"\"\"Computes micro-averaged precision.\"\"\"\n",
    "    tp_sum = sum(tp.values())\n",
    "    fp_sum = sum(fp.values())\n",
    "    return tp_sum / (tp_sum + fp_sum)\n",
    "\n",
    "\n",
    "def micro_recall(tp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "    \"\"\"Computes micro-averaged recall.\"\"\"\n",
    "    tp_sum = sum(tp.values())\n",
    "    fn_sum = sum(fn.values())\n",
    "    return tp_sum / (tp_sum + fn_sum)\n",
    "\n",
    "\n",
    "def micro_f1(tp: \"dict[str, int]\", fp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "    \"\"\"Computes micro-averaged F1.\"\"\"\n",
    "    mp = micro_precision(tp, fp)\n",
    "    mr = micro_recall(tp, fn)\n",
    "    return 2 * (mp * mr) / (mp + mr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNG8QyAnyE1L"
   },
   "source": [
    "### Macro-Averaged Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1759511632446,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "aOdvkruIyE1L"
   },
   "outputs": [],
   "source": [
    "def macro_precision(tp: \"dict[str, int]\", fp: \"dict[str, int]\") -> float:\n",
    "    \"\"\"Computes macro-averaged precision.\"\"\"\n",
    "    n = len(tp)\n",
    "    return (1 / n) * sum([precision(tp[c], fp[c]) for c in tp.keys()])\n",
    "\n",
    "\n",
    "def macro_recall(tp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "    \"\"\"Computes macro-averaged recall.\"\"\"\n",
    "    n = len(tp)\n",
    "    return (1 / n) * sum([recall(tp[c], fn[c]) for c in tp.keys()])\n",
    "\n",
    "\n",
    "def macro_f1(tp: \"dict[str, int]\", fp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "    \"\"\"Computes macro-averaged F1.\"\"\"\n",
    "    n = len(tp)\n",
    "    return (\n",
    "        2\n",
    "        * (macro_precision(tp, fp) * macro_recall(tp, fn))\n",
    "        / (macro_precision(tp, fp) + macro_recall(tp, fn))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60uRaPkSyE1L"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5JenndHyE1L"
   },
   "source": [
    "### Loading data from files\n",
    "\n",
    "We first need to load data from the provided TSV files. Each file is two columns, the language of the document and the document text, separated by a tab (`\\t`) character. We load this data into a list of tuples, to maintain the coupling between each document and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1759511632508,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "expfX6fGyE1M"
   },
   "outputs": [],
   "source": [
    "def load_data(data_filename: str) -> list[tuple[str, str]]:\n",
    "    with open(data_filename, 'r', errors='backslashreplace', encoding='utf-8') as f_in:\n",
    "        language_document_tuples = [(line.split(\"\\t\")[0], line.split(\"\\t\")[1]) for line in f_in.read().split(\"\\n\") if line != '']\n",
    "    return language_document_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3Y6mfWfyE1M"
   },
   "source": [
    "### Feature Extraction\n",
    "\n",
    "We will use ngrams as features, so we need to be able to extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1759511632540,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "nQYIOr2NyE1M"
   },
   "outputs": [],
   "source": [
    "def extract_ngrams(x: str, n=3) -> \"list[str]\":\n",
    "    \"\"\"Given a string, return all character ngrams of order `n`.\"\"\"\n",
    "    return [\"\".join(s) for s in (zip(*[x[i:] for i in range(n)]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkIdpen-yE1M"
   },
   "source": [
    "### Language Codes to One-Hot Vectors\n",
    "And we need a function to convert a language code into a **one-hot vector** (called $\\mathbf{y}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1759511632543,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "RSynlhE0yE1M"
   },
   "outputs": [],
   "source": [
    "def to_onehot_vector(lang: str, langs: list[str]) -> np.ndarray:\n",
    "    y = np.zeros(len(langs))\n",
    "    y[langs.index(lang)] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZPNsUJ0yE1M"
   },
   "source": [
    "We need to be able to convert `dict`s of ngram counts to vectors of ngram counts (using a map from ngrams to dimensions of the vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759511632547,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "4eLNWl8iyE1M"
   },
   "outputs": [],
   "source": [
    "def vectorize_ngrams(counter: dict[str, int], feature_map: dict[str, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a dict of ngram counts and a map from features to indices, returns a vector of ngram counts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counter : dict\n",
    "        Counter/dict of ngram counts\n",
    "    feature_map : dict\n",
    "        Map from ngrams to indices\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A vector of ngram counts\n",
    "    \"\"\"\n",
    "    feature_vector = np.zeros(len(feature_map))\n",
    "    for ngram, count in counter.items():\n",
    "        if ngram in feature_map:\n",
    "            feature_vector[feature_map[ngram]] = count\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-A2mO8_yE1M"
   },
   "source": [
    "And putting together the conversion from text into ngrams, and vectorizing the ngrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1759511632584,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "AbTp6E5IyE1M"
   },
   "outputs": [],
   "source": [
    "def vectorize_document(document: str, feature_map: dict[str, int], ngram_length: int) -> np.ndarray:\n",
    "    document_ngrams = extract_ngrams(document, ngram_length)\n",
    "    vector = vectorize_ngrams(Counter(document_ngrams), feature_map)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2czxhma2yE1M"
   },
   "source": [
    "We need separate functions for preprocessing the training observations and the dev/test observations. The former function must return a map from language names to labels as one-hot vectors as well as a map from features (ngrams) to indices of vector dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1759511632585,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "xJ4N-OLbyE1M"
   },
   "outputs": [],
   "source": [
    "def preprocess_training_observations(\n",
    "    training_observations: list[tuple[str, str]], n: int = 1\n",
    ") -> tuple[list[tuple[np.ndarray, np.ndarray]], dict[str, np.ndarray], dict[str, int]]:\n",
    "    langs = set()\n",
    "    features = set()\n",
    "    obs = []\n",
    "\n",
    "    for lang, doc in training_observations:\n",
    "        langs.add(lang)\n",
    "        ngrams = extract_ngrams(doc, n)\n",
    "        features = features | set(ngrams)\n",
    "        obs.append((lang, ngrams))\n",
    "    feature_map = {feature: idx for idx, feature in enumerate(sorted(features))}\n",
    "    lang_list = list(sorted(langs))\n",
    "    lang_map = {lang: to_onehot_vector(lang, lang_list) for lang in lang_list}\n",
    "\n",
    "    obs = [\n",
    "        (lang_map[lang], vectorize_ngrams(Counter(ngrams), feature_map)) for (lang, ngrams) in obs\n",
    "    ]\n",
    "\n",
    "    # print(\"Obs:\", obs[0])\n",
    "    # print(\"Lang Map:\", lang_map, \"\\n\")\n",
    "\n",
    "    # print(\"Training observations Lang:\", training_observations[0][0], \"\\n\")\n",
    "    # print(\"Training observations doc:\", training_observations[0][1])\n",
    "\n",
    "    print(f\"{len(obs)} training observations.\")\n",
    "    return obs, lang_map, feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDikqEOJyE1N"
   },
   "source": [
    "The function for preprocessing test observations (and dev observations) takes the feature map and the language map as arguments and returns only the list of labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759511632589,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "SiMQaZ4gyE1N"
   },
   "outputs": [],
   "source": [
    "def preprocess_test_observations(\n",
    "    test_observations, feature_map: dict[str, int], lang_map: dict[str, np.ndarray], n: int = 1\n",
    ") -> tuple[list[np.ndarray], list[np.ndarray]]:\n",
    "    obs = []\n",
    "\n",
    "    for i, (lang, doc) in enumerate(test_observations):\n",
    "        vectorized_doc = vectorize_document(doc, feature_map, ngram_length=n)\n",
    "        try:\n",
    "            obs.append((lang_map[lang], vectorized_doc))\n",
    "        except KeyError:\n",
    "            print(f\"Unkown language {lang} at index {i}. Known languages are: {lang_map.keys()}\")\n",
    "    print(f\"{len(obs)} test observations.\")\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsIWr3b4yE1N"
   },
   "source": [
    "### Classification Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAlUSgMTyE1N"
   },
   "source": [
    "We also need to define the softmax function.\n",
    "\n",
    "Softmax is technically\n",
    "\n",
    "$$\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum^K_{j=1} e^{z_j}}$$\n",
    "\n",
    "However, if implemented naïvely, this is not numerically stable. Instead, we use:\n",
    "\n",
    "$$\\text{softmax}(z_i) = \\frac{e^{z_i - \\text{max}(z)}}{\\sum^K_{j=1} e^{z_j - \\text{max}(z)}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1759511632600,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "Dz2KGujgyE1N"
   },
   "outputs": [],
   "source": [
    "def softmax(z: npt.ArrayLike) -> npt.ArrayLike:\n",
    "    \"\"\"Compute the softmax of a vector `z`\"\"\"\n",
    "    # exp(z) can get very large. For numerical stability, we subtract a vector of very large values (np.max(z)) from z.\n",
    "    return np.exp(z - np.max(z)) / np.exp(z - np.max(z)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmmpqXV2yE1N"
   },
   "source": [
    "## Training the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzWD7RGCyE1N"
   },
   "source": [
    "### Compute the gradient\n",
    "\n",
    "The formula for computing one element in our gradient is as follows (the partial derivitive of the negative log likelihood loss):\n",
    "\n",
    "$$\\frac{\\partial L_{CE}}{\\partial \\mathbf{w}_{k,i}}=-(\\mathbf{y}_k-\\hat{\\mathrm{y}}_k)\\mathbf{x}_i$$\n",
    "\n",
    "where $k$ is the **class** (rows of the matrix $\\mathbf{w}$) and $i$ corresponds the the feature (columns of the matrix $\\mathbf{w}$).\n",
    "\n",
    "We will define a function `grad` for computing the whole gradient, a $K \\times N$ matrix.\n",
    "\n",
    "**This is the first piece of code that you'll write.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759511632602,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "rUTieBtDyE1N",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [],
   "source": [
    "def grad(W: np.ndarray, y: np.ndarray, x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Caculates the gradient of the negative log liklihood loss, a [K * N] matrix, with respect to W.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : np.ndarray\n",
    "        A matrix of of weights, expressed as a [K * N] matrix where K is the number of classes and N is the number of features.\n",
    "    y : np.ndarray\n",
    "       The true label of the observation, expressed as a one-hot encoded vector of shape [K].\n",
    "    x : np.ndarray\n",
    "        A vector of features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The gradient of the loss with respect to W.\n",
    "    \"\"\"\n",
    "\n",
    "    # Grad = -(Yk - Y_hat)Xi\n",
    "    # Yk = rows of W\n",
    "    # Y_hat = cols of W\n",
    "    # Xi = a single feature vector x\n",
    "\n",
    "    # z = w . x + b\n",
    "    x = x.flatten() # flatten x to turn it to a matrix of 1-dimensional matrix for multiplication\n",
    "    # print(\"Gradient: x flatten:\", x, \"\\n\")\n",
    "    z = np.matmul(W, x)\n",
    "\n",
    "    # print(\"grad() z: \", z, \"\\n\")\n",
    "\n",
    "    # Y_hat = softmax(z)\n",
    "    Y_hat = softmax(z)\n",
    "\n",
    "    # error = (Yk - Y_hat)\n",
    "    error = y - Y_hat\n",
    "\n",
    "    # print(\"Error:\", error)\n",
    "\n",
    "    # grad = -(Yk - Y_hat)Xi\n",
    "    grad = -np.outer(error, x)\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsWLPhtnyE1N"
   },
   "source": [
    "### Training Loop\n",
    "\n",
    "Iterate over the observations in the training set $n$ times (in random order). For each item, compute the one-hot vector $\\mathbf{y}$ and the probability distribution $\\hat{\\mathbf{y}}$. Use these values to compute the gradient. Update the parameters based on the gradient. At the end of each epoch (pass through the training data), compute the true positives, false positives, and false negatives for each target class based on the current weights, and report micro-averaged precision and recall.\n",
    "\n",
    "**Note**: The way that we evaluated the training loop depended on an in-place shuffle of the training data, which, while not technically wrong, is maybe not the most intuitive way to do it. When shuffling your data, please either use a shuffling method that does not change the observations parameter in-place. In particular, please use `random.sample` like:\n",
    "```\n",
    "shuffled_observations = random.sample(observations, len(observations))\n",
    "```\n",
    "\n",
    "How you report the metrics is up to you — we will not look at what you output to STDOUT — but it is important that you do this. **Otherwise, you will not be able to determine whether your model is training.**\n",
    "\n",
    "You can also output the loss at each step (very noisy!), each epoch, or run the classifier on the dev set and report the metrics at the end of each epoch.\n",
    "\n",
    "Remember that the 0th column in $W$ contains the biases. You will have to insert a $1$ at the beginning of the feature vector $x$ in order to accomodate this.\n",
    "\n",
    "### Important Note About Bias Terms\n",
    "\n",
    "Your weight matrix W will have shape [K, N+1] where the first column (index 0) contains bias terms for each class. When computing gradients and making predictions, you must:\n",
    "\n",
    "1. **Prepend 1 to your feature vectors** to account for the bias term\n",
    "2. **Initialize W with an extra column** for bias terms\n",
    "3. **Remember this when vectorizing documents for prediction**\n",
    "\n",
    "Example: If your feature vector x has shape [1000], prepend 1 to make it shape [1001] before matrix multiplication with W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759511632603,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "qt8b3a7dyE1N",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [],
   "source": [
    "def train(observations: list[tuple[np.ndarray, np.ndarray]], eta: float, epochs: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a set of observations, returns a trained multinomial LR (softmax regression) model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : list[tuple[np.ndarray, np.ndarray]]\n",
    "        A list of tuples, where each tuple contains (y, x):\n",
    "        - y: one-hot vector encoding the ground truth language label (shape [K])\n",
    "        - x: vector of features (shape [N])\n",
    "        Note: Remember to add bias term (prepend 1 to x) when computing gradients.\n",
    "    eta : float\n",
    "        Learning rate for gradient descent.\n",
    "    epochs : int\n",
    "        The number of epochs to train the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The trained model as a [K * N] weight matrix, where column 0 contains bias terms.\n",
    "    \"\"\"\n",
    "\n",
    "    # Shape [K] = 6 (6 languages)\n",
    "    # y: (swahili, manobo, nahuatl, hausa, tagalog, indomesian) e.g [1 0 0 0 0 0]\n",
    "    # x: vector of features (Unatakiwa ukumbuke kuwa ulikuwa mtumwa katika nchi ya Misri; kwa hiyo nakuagiza kutii amri hii.)\n",
    "\n",
    "    # onehot_vector e.g [0, 0, 0, 0, 1, 0] shape K\n",
    "    onehot_vector = observations[0][0]\n",
    "\n",
    "    # features_vector e.g [0. 0, 0, 1, 0, 1, 0, 12, 14, 18, 45] shape N\n",
    "    features_vector = observations[0][1]\n",
    "\n",
    "    # initialize W with an extra column for bias terms (W = K X N)\n",
    "    weights_matrix = np.zeros((onehot_vector.shape[0], features_vector.shape[0]+1))\n",
    "\n",
    "\n",
    "    for step in range(epochs):\n",
    "        shuffled_observations = random.sample(observations, len(observations))\n",
    "\n",
    "        for observation in shuffled_observations:\n",
    "            onehot_vec = observation[0]\n",
    "            features_vec = observation[1]\n",
    "\n",
    "            biased_features_vec = np.concatenate(([1], features_vec)) # prepend 1 to features vector to account for bias terms\n",
    "\n",
    "            # print(\"One hot vector\", onehot_vec, \"\\n\")\n",
    "            # print(\"Feature vector\", features_vec, \"\\n\")\n",
    "\n",
    "            gradient = grad(weights_matrix, onehot_vec, biased_features_vec)\n",
    "\n",
    "            weights_matrix -= eta * gradient\n",
    "\n",
    "    return weights_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYlrRD2iyE1O"
   },
   "source": [
    "## Classification\n",
    "\n",
    "The classification function is very simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1759511632626,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "cXDadimZyE1O",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [],
   "source": [
    "def classify(W: np.ndarray, x: np.ndarray) -> np.intp:\n",
    "    \"\"\"\n",
    "    Return the index of the hypothesized language.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : np.ndarray\n",
    "        Weight matrix (one row for each category/language, on column for each feature)\n",
    "    x : np.ndarray\n",
    "        Vector of real-valuled features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    intp\n",
    "        The index of the hypothesized language.\n",
    "    \"\"\"\n",
    "\n",
    "    # Z = W . X + b\n",
    "    # biased_x = X + b\n",
    "    biased_x = np.concatenate(([1], x))\n",
    "\n",
    "    # z = W . (x + b)\n",
    "    z = np.dot(W, biased_x)\n",
    "\n",
    "    # print(\"Argmax \", np.argmax(z))\n",
    "\n",
    "    return np.argmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvS-HsSyyE1O"
   },
   "source": [
    "## Evaluate the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVr5HQUzyE1O"
   },
   "source": [
    "Then, a function to train and evaluate the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1759511632629,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "JfBmJWlQyE1O"
   },
   "outputs": [],
   "source": [
    "def evaluate(train_set, test_set, eta, epochs=3):\n",
    "    \"\"\"Trains and evaluates a model.\"\"\"\n",
    "    print(\"Training model\")\n",
    "    W = train(train_set, eta, epochs=epochs)\n",
    "    print(\"\\nCLASSIFY\")\n",
    "    tp, fp, fn = Counter(), Counter(), Counter()\n",
    "    for ref_lang_vec, x in test_set:\n",
    "        # print(\"Ref lang vec\", ref_lang_vec)\n",
    "        ref_lang = np.argmax(ref_lang_vec)\n",
    "        # print(\"Ref lang \", ref_lang)\n",
    "\n",
    "        hyp_lang = classify(W, x)\n",
    "        # print(\"hyp_lang lang \", hyp_lang)\n",
    "        if hyp_lang == ref_lang:\n",
    "            tp[ref_lang] += 1\n",
    "        else:\n",
    "            fp[hyp_lang] += 1\n",
    "            fn[ref_lang] += 1\n",
    "    # Print metrics\n",
    "\n",
    "    test_macro_f1 = macro_f1(tp, fp, fn)\n",
    "    test_micro_f1 = micro_f1(tp, fp, fn)\n",
    "    print(f\"macro-averaged F1:\\t\\t{test_macro_f1:.3f}\")\n",
    "    print(f\"micro-averaged F1:\\t\\t{test_micro_f1:.3f}\")\n",
    "    return test_macro_f1, test_micro_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_Yi3u7fyE1O"
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt6pGjk-yE1O"
   },
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3428,
     "status": "ok",
     "timestamp": 1759511636058,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "F9ppF8bXyE1O",
    "outputId": "1671ac75-9ea7-47ec-ce8f-9d31004879b7"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_observations = load_data('train.tsv')\n",
    "test_observations = load_data('test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zOiLs2IyE1P"
   },
   "source": [
    "### Inspecting the data\n",
    "\n",
    "Before we actually train the classifier, it's important to look at your data, and check that any assumptions you're making about it are justified. It's always useful at this point to check basic things, like:\n",
    "- How many instances of train and test data do you have?\n",
    "- What labels are in your data, and do those match between the train and test splits?\n",
    "- What is the class balance (i.e. how many instances of each class) in your dataset? Is it balanced or unbalanced?\n",
    "\n",
    "Output a dictionary for the train and test data that maps each label to the count of instances that have that label, e.g.:\n",
    "```\n",
    "{\"hausa\": 4000, \"indonesian\":...}\n",
    "```\n",
    "\n",
    "Your dictionary should be sorted in descending order of occurrence of languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1759511636080,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "SGEpfqiFyE1P",
    "outputId": "be02dd97-0a27-48bf-b1c3-6b5247570923",
    "output_for": "1.1",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'swahili': 411, 'tagalog': 391, 'manobo': 114, 'hausa': 98, 'nahuatl': 93, 'indonesian': 93}\n"
     ]
    }
   ],
   "source": [
    "# this cell's output will be used for test 1.1\n",
    "# your code here - train set\n",
    "langs = []\n",
    "for obs in train_observations:\n",
    "    langs.append(obs[0])\n",
    "\n",
    "train_dict = dict(Counter(langs))\n",
    "sorted_dict = sorted(train_dict.items(), key=lambda item:item[1], reverse=True)\n",
    "\n",
    "print(dict(sorted_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1759511636097,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "7ec4VSKgyE1P",
    "outputId": "1465f1cd-b477-432a-8141-b81922041b38",
    "output_for": "1.2",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'swahili': 148, 'tagalog': 121, 'nahuatl': 37, 'manobo': 34, 'indonesian': 32, 'hausa': 28}\n"
     ]
    }
   ],
   "source": [
    "# this cell's output will be used for test 1.2\n",
    "# your code here - test set\n",
    "langs = []\n",
    "for obs in test_observations:\n",
    "    langs.append(obs[0])\n",
    "\n",
    "train_dict = dict(Counter(langs))\n",
    "sorted_dict = sorted(train_dict.items(), key=lambda item:item[1], reverse=True)\n",
    "\n",
    "print(dict(sorted_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rETq5USgyE1P"
   },
   "source": [
    "### Set hyperparameters and parameters\n",
    "\n",
    "Before training the model, we have to set the learning rate $\\eta$ and the order of the ngrams used in feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1759511636116,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "d26VTkykyE1P"
   },
   "outputs": [],
   "source": [
    "eta = 0.0005  # Do not change this.\n",
    "epochs = 4  # Do not change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1759511636157,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "JmCmuEpXQ3V7"
   },
   "outputs": [],
   "source": [
    "order_of_ngrams = 2  # Change this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35um7JeyyE1P"
   },
   "source": [
    "### Running our training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7XNyGzmyE1P"
   },
   "source": [
    "Now train your classifier, and evaluate it on the test set. Vary the number of ngrams, and observe how it changes train and test F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1759511636683,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "ITzdOoUHyE1P",
    "outputId": "9e8beb6d-f790-4208-ef35-355f1b18f94c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 training observations.\n",
      "400 test observations.\n",
      "Training model\n",
      "\n",
      "CLASSIFY\n",
      "macro-averaged F1:\t\t0.976\n",
      "micro-averaged F1:\t\t0.985\n"
     ]
    }
   ],
   "source": [
    "train_set, lang_map, feature_map = preprocess_training_observations(\n",
    "    train_observations, n=order_of_ngrams\n",
    ")\n",
    "test_set = preprocess_test_observations(test_observations, feature_map, lang_map, n=order_of_ngrams)\n",
    "\n",
    "# print(\"Train set\", train_set[1], \"\\n\")\n",
    "\n",
    "# print(\"Test set\", test_set[1])\n",
    "\n",
    "random.seed(27)\n",
    "test_macro_f1, test_micro_f1 = evaluate(train_set, test_set, eta, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4FNpx3JyE1P"
   },
   "source": [
    "Print the tuple of the best values of `(macro_f1, micro_f1)` for the model evaluated on your test set while varying the order of the ngrams. What value of n produced the best result? Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1759511636708,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "Pl3218WryE1P",
    "outputId": "2aeba34e-4424-4bad-a95d-7cfb40b67fb0",
    "output_for": "2.1",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9757823365261366, 0.985)\n"
     ]
    }
   ],
   "source": [
    "# the output of this cell will be used for test 2.1\n",
    "print((test_macro_f1, test_micro_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADbxCAlLyE1P"
   },
   "source": [
    "## Inspecting Classification Results\n",
    "\n",
    "We've trained our classifier, and your final F1 should be pretty close to 1.0. Great job! But what does that mean for the languages you're actually classifying? Let's rewrite our evaluation code to allow us to look at our results instance-by-instance. For this, we're going to examine the results of a re-trained trigram classifier, trained for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1759511637609,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "5eQAaoAYyE1Q",
    "outputId": "1943e527-ba3f-4cb2-ba56-32feb379f89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 training observations.\n",
      "400 test observations.\n",
      "macro-averaged F1:\t\t0.946\n",
      "micro-averaged F1:\t\t0.960\n"
     ]
    }
   ],
   "source": [
    "# Re-training a trigram classifier. Do not change this.\n",
    "\n",
    "INSPECTION_NGRAMS = 3\n",
    "\n",
    "train_set, lang_map, feature_map = preprocess_training_observations(\n",
    "    train_observations, n=INSPECTION_NGRAMS\n",
    ")\n",
    "test_set = preprocess_test_observations(\n",
    "    test_observations, feature_map, lang_map, n=INSPECTION_NGRAMS\n",
    ")\n",
    "\n",
    "random.seed(27)\n",
    "W_inspect = train(train_set, eta, epochs=1)\n",
    "\n",
    "## evaluate it as before. Check that this looks the same!\n",
    "tp, fp, fn = Counter(), Counter(), Counter()\n",
    "for ref_lang_vec, x in test_set:\n",
    "    ref_lang = np.argmax(ref_lang_vec)\n",
    "\n",
    "    hyp_lang = classify(W_inspect, x)\n",
    "    if hyp_lang == ref_lang:\n",
    "        tp[ref_lang] += 1\n",
    "    else:\n",
    "        fp[hyp_lang] += 1\n",
    "        fn[ref_lang] += 1\n",
    "# Print metrics\n",
    "\n",
    "print(f\"macro-averaged F1:\\t\\t{macro_f1(tp, fp, fn):.3f}\")\n",
    "print(f\"micro-averaged F1:\\t\\t{micro_f1(tp, fp, fn):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21Z8m6YVyE1Q"
   },
   "source": [
    "### Writing a prediction function\n",
    "\n",
    "Write a function that takes a list of observations, and produces a list of either class indices, or class names based on a parameter. This will allow you both to look at individual results from evaluating on an existing set of data (like the test set), but also for you to evaluate your classifier on new data (i.e. any string). This will involve vectorizing the list of documents, and classifying those vectors. Once that's complete, construct an inverse language mapping, from predicted indices to the language they represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759511637611,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "AQZHWlX7yE1Q",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "    documents: list[str],\n",
    "    W: np.ndarray,\n",
    "    feature_map: dict[str, int],\n",
    "    lang_map: dict[str, np.ndarray],\n",
    "    ngram_length: int,\n",
    "    return_class_names=False,\n",
    "):\n",
    "    # your code here\n",
    "\n",
    "    # print(\"Lang map\", lang_map)\n",
    "    # print(\"W in vectorize\", W)\n",
    "\n",
    "    lang_dict = {idx: lang for lang, onehot_vec in lang_map.items() for idx, vec in enumerate(onehot_vec) if vec == 1}\n",
    "    # print(\"Lang dict\", lang_dict, \"\\n\")\n",
    "    predictions = []\n",
    "    for doc in documents:\n",
    "        x = vectorize_document(doc, feature_map, ngram_length)\n",
    "        # print(\"X in vectorize\", x)\n",
    "        lang_idx = classify(W, x)\n",
    "        # print(\"Classify:\", lang_idx)\n",
    "        if return_class_names:\n",
    "            predictions.append(lang_dict[lang_idx])\n",
    "        else:\n",
    "            predictions.append(lang_idx)\n",
    "\n",
    "    # print(\"Predictions:\", predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "924RYujfyE1Q"
   },
   "source": [
    "Now, for each instance in the test set, print a tuple of the actual label, then the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1759511637631,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "bPbGtDUayE1Q",
    "outputId": "92d2207d-8e41-41c3-f860-ee2272efda6a",
    "output_for": "3.1",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('swahili', 'swahili'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('hausa', 'hausa'), ('nahuatl', 'nahuatl'), ('hausa', 'hausa'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('hausa', 'swahili'), ('indonesian', 'indonesian'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('indonesian', 'indonesian'), ('nahuatl', 'nahuatl'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('hausa', 'hausa'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('tagalog', 'swahili'), ('manobo', 'manobo'), ('manobo', 'manobo'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('indonesian', 'indonesian'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('hausa', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('manobo', 'manobo'), ('nahuatl', 'nahuatl'), ('indonesian', 'indonesian'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('hausa', 'hausa'), ('hausa', 'hausa'), ('hausa', 'hausa'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('indonesian', 'indonesian'), ('hausa', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'tagalog'), ('nahuatl', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('hausa', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('hausa', 'hausa'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('hausa', 'hausa'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('hausa', 'hausa'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('hausa', 'hausa'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('hausa', 'hausa'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('nahuatl', 'swahili'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('hausa', 'hausa'), ('swahili', 'swahili'), ('hausa', 'indonesian'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('indonesian', 'indonesian'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('hausa', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('nahuatl', 'nahuatl'), ('indonesian', 'indonesian'), ('manobo', 'manobo'), ('manobo', 'swahili'), ('indonesian', 'indonesian'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('hausa', 'swahili'), ('manobo', 'manobo'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('hausa', 'hausa'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('hausa', 'hausa'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('hausa', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('indonesian', 'indonesian'), ('hausa', 'hausa'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('nahuatl', 'nahuatl'), ('tagalog', 'tagalog'), ('hausa', 'hausa'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('hausa', 'hausa'), ('hausa', 'hausa'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('hausa', 'swahili'), ('hausa', 'swahili'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('nahuatl', 'nahuatl'), ('indonesian', 'indonesian'), ('manobo', 'manobo'), ('nahuatl', 'nahuatl'), ('swahili', 'swahili'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('manobo', 'manobo'), ('swahili', 'swahili'), ('manobo', 'manobo'), ('tagalog', 'tagalog'), ('swahili', 'swahili'), ('swahili', 'swahili'), ('tagalog', 'tagalog'), ('indonesian', 'indonesian'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('tagalog', 'tagalog'), ('swahili', 'swahili')]\n"
     ]
    }
   ],
   "source": [
    "# the output of this cell will be used for test 3.1\n",
    "test_labels, test_documents = zip(*test_observations)\n",
    "test_predictions = predict(\n",
    "    test_documents,\n",
    "    W_inspect,\n",
    "    feature_map,\n",
    "    lang_map,\n",
    "    ngram_length=INSPECTION_NGRAMS,\n",
    "    return_class_names=True,\n",
    ")\n",
    "\n",
    "print(list(zip(test_labels, test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HH5VlGV2yE1Q"
   },
   "source": [
    "### Plotting a Confusion Matrix\n",
    "\n",
    " A _confusion matrix_ is a $k \\times k$ matrix, where k is your number of classes, where the cell in position $(i,j)$ counts the number of instances that belong to class $i$ that were predicted to be in class $j$. The diagonal entries represent correct classifications; anything off of the diagonal represents an incorrect classification. The example below, from the [scikit learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html), shows a confusion matrix for a binary classification problem.\n",
    "\n",
    "![A confusion matrix for a binary classification problem](confusion_matrix.png)\n",
    "\n",
    "\n",
    "Confusion matrices can be useful to see what types of errors your classifier is making. If errors are concentrated into particular cells, it could indicate the kind of data that your classifier struggles with. Write a function to take a list of test observations, and output a numpy array that represents your classifier's confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1759511637632,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "YAjrzsrVyE1Q"
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix(\n",
    "    labels: list[str], predictions: list[str], lang_map: dict[str, np.ndarray]\n",
    ") -> np.ndarray:\n",
    "    # your code here\n",
    "\n",
    "    lang_list = sorted(lang_map.keys())\n",
    "\n",
    "    lang_to_idx = {lang: idx for idx, lang in enumerate(lang_list)}\n",
    "    # print(\"Lang indx\", lang_to_idx)\n",
    "    num_langs = len(lang_list)\n",
    "\n",
    "    matrix = np.zeros((num_langs, num_langs), dtype=int)\n",
    "\n",
    "    for true_label, pred_label in zip(labels, predictions):\n",
    "        # print(\"True label\", true_label)\n",
    "        # print(\"Predicted label\", pred_label)\n",
    "\n",
    "        i = lang_to_idx[true_label]\n",
    "        j = lang_to_idx[pred_label]\n",
    "\n",
    "        matrix[i, j] += 1\n",
    "\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBT2kw9UyE1Q"
   },
   "source": [
    "Now, print your confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1759511637664,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "UWUEm2gLyE1Q",
    "outputId": "cbf97274-2cfb-477b-b28e-609a9c911c76",
    "output_for": "3.2",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18,   1,   0,   0,   9,   0],\n",
       "       [  0,  31,   0,   0,   0,   1],\n",
       "       [  0,   0,  32,   0,   1,   1],\n",
       "       [  0,   0,   0,  35,   2,   0],\n",
       "       [  0,   0,   0,   0, 148,   0],\n",
       "       [  0,   0,   0,   0,   1, 120]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output of this cell will be used for test 3.2\n",
    "get_confusion_matrix(test_labels, test_predictions, lang_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJ3tsbqqyE1Q"
   },
   "source": [
    "From your confusion matrix, how many Hausa examples are misclassified as Swahili? Print each of the misclassified documents on a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1759511637668,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "yQT9ECjIyE1R",
    "outputId": "955c17e3-9c51-4724-bdf3-0b5e47a78776",
    "output_for": "3.3",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dalilin haka kuwa sun nuna cewa ayukan da shari'a take bukata na nan a rubuce a zuciyarsu. lamirinsu kuma na yi masu shaida, tunanainsu kuma, ko dai yana kashe su, ko kuma yana karesu.\n",
      "Sai aka kawo kansa bisa tire, aka mika wa yarinyar, ta kuwa kai wa mahaifiyarta.\n",
      "Baku sani ba mu za mu yiwa mala'iku shari'a? Balle shari'ar al'amuran wannan rai?\n",
      "Da suka kai su Kotu, suka ce, ''Wadannan mutane Yahudawa ne, suna kawo tashin hankali a birninmu.\n",
      "Ya ce masu, \"A rubuce yake, cewa Almasihu za ya sha wuya, zai tashi kuma daga matattu a rana ta uku.\n",
      "Bayan shekara uku na je Urushalima don in san Kefas, na zauna da shi na kwana goma sha biyar.\n",
      "Ga wani yin ayyukan iko, ga wani kuwa annabci. Ga wani kuwa an ba shi baiwar bambance ruhohi, ga wani harsuna daban daban, kuma ga wani fassarar harsuna.\n",
      "Amma da hankalinsa ya dawo, ya ce, 'Barorin mahaifina su nawa ne da suke da abinci isasshe, amma ina nan a nan, ina mutuwa sabili da yunwa!\n",
      "Wannan dabban da na gani yana kama da damisa, kafafunsa kuma kamar na beyar, bakinsa kuma kamar na zaki. Wannan diragon ya ba shi karfinsa, da kursiyinsa da ikonsa mai girma na sarauta.\n",
      "\n",
      "Number of Hausa examples misclassified as Swahili: 9\n"
     ]
    }
   ],
   "source": [
    "# the output of this cell will be used for test 3.3\n",
    "# your code here\n",
    "lang_list = sorted(lang_map.keys())\n",
    "hausa_index = lang_list.index('hausa')\n",
    "# swahili_index = lang_list.index('swahili')\n",
    "\n",
    "misclassified_documents = []\n",
    "\n",
    "# print(\"Test set:\", test_set, \"\\n\")\n",
    "\n",
    "# print(\"Test observations\", test_observations)\n",
    "\n",
    "for index, (true_label_vec, doc_vector) in enumerate(test_set):\n",
    "\n",
    "    true_label_index = np.argmax(true_label_vec)\n",
    "    true_label = lang_list[true_label_index]\n",
    "\n",
    "    hyp_label_index = classify(W_inspect, doc_vector)\n",
    "    hyp_label = lang_list[hyp_label_index]\n",
    "\n",
    "    if true_label == 'hausa' and hyp_label == 'swahili':\n",
    "\n",
    "        misclassified_doc = test_observations[index][1]\n",
    "        misclassified_documents.append(misclassified_doc)\n",
    "\n",
    "\n",
    "for doc in misclassified_documents:\n",
    "    print(doc)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nNumber of Hausa examples misclassified as Swahili:\", len(misclassified_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxINVZHDyE1R"
   },
   "source": [
    "Can you formulate a hypothesis for why these Hausa examples are being misclassified as Swahili? Peruse the Wikipedia pages of the two languages, and inspect the data and features of the two languages. Consider reasons based in what you know about the languages, and about machine learning. Try to come up with 2-3 experiments you might run to validate your hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LarqWkqQyE1R"
   },
   "source": [
    "### Examining Feature Weights\n",
    "\n",
    "The classifier that we've built for softmax classification behaves in many ways like using several binary softmax classifiers stacked together. The $K \\times N$ weight matrix `W_inspect` (from the trigram classifier trained above) can be interpreted as a $1 \\times N$ feature vector for each class, where each row represents the weights for one language class.\n",
    "\n",
    "**Important: Use the `W_inspect` matrix from the \"Inspecting Classification Results\" section above for this analysis.**\n",
    "\n",
    "In this section, we'll examine the weights for a few of our classified languages. To get feature names out of these vectors, we'll construct an inverted feature map, that maps indices in the feature vectors back to n-grams. Then, extract the $1 \\times N$ vector that corresponds to Hausa (one row from `W_inspect`). Print the shape of the Hausa feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759511637675,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "FL8Pl5iPyE1R",
    "outputId": "312e4f77-8edf-4be3-aeba-36de7ab2de78",
    "output_for": "4.1",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7814,)\n"
     ]
    }
   ],
   "source": [
    "# the output of this cell will be used for test 4.1\n",
    "# Invert the feature map\n",
    "inverted_feature_map = {v: k for k, v in feature_map.items()}\n",
    "\n",
    "# your code here\n",
    "\n",
    "# Get the index for the Hausa language from the lang map\n",
    "hausa_index = np.argmax(lang_map['hausa'])\n",
    "# print(\"Hausa index\", hausa_index)\n",
    "\n",
    "# Get the feature vector for Hausa from the weight matrix W_inspect excluding the bias term\n",
    "hausa_feature_vector = W_inspect[hausa_index, 1:] \n",
    "\n",
    "# print(\"Hausa feature vec\", hausa_feature_vector)\n",
    "\n",
    "print(hausa_feature_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l46owXayE1R"
   },
   "source": [
    "Now, let's find the features that are most strongly predictive of an instance being Hausa. From the Hausa feature vector, find the names of the features with the top-10 positive values. Print your results with a tuple of (feature name, feature_weight) on each line:\n",
    "```\n",
    "(\"aaa\", 0.04597442104739769)\n",
    "(\"bbb\", 0.03454984682736487)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759511637679,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "ALnp3khdyE1R",
    "outputId": "558792c5-3fe5-42fc-883f-4473b74d5bfc",
    "output_for": "4.2",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('da ', 0.06451164031068245)\n",
      "(' da', 0.05814918884378874)\n",
      "('in ', 0.032426575762492936)\n",
      "(' ba', 0.02643611391809732)\n",
      "('ar ', 0.02555232352139255)\n",
      "(' ya', 0.024015673618085424)\n",
      "(' sh', 0.021499026046531342)\n",
      "('ai ', 0.02050666010795031)\n",
      "('ya ', 0.019389629427255823)\n",
      "(' su', 0.018342154705746547)\n"
     ]
    }
   ],
   "source": [
    "# the output of this cell will be used for test 4.2\n",
    "# your code here\n",
    "\n",
    "hausa_feature_vector = W_inspect[hausa_index, 1:] \n",
    "\n",
    "# print(\"hausa_feature_vector\", hausa_feature_vector, \"\\n\")\n",
    "\n",
    "top_indices_with_bias = np.argsort(hausa_feature_vector[1:])[-10:] # get the indices that would sort the array of feature vectors with bias\n",
    "\n",
    "# print(\"Top 10 indices with bias\", top_indices_with_bias, \"\\n\")\n",
    "\n",
    "top_indices_with_bias = top_indices_with_bias[::-1] # flip the indices to turn asxending to become descendng order\n",
    "\n",
    "# print(\"Top 10 indices with bias desc\", top_indices_with_bias, \"\\n\")\n",
    "\n",
    "top_10_indices = top_indices_with_bias + 1 # add 1 to account for the bias term that was removed\n",
    "\n",
    "\n",
    "# get the features corresponding to the top 10 indices using the inverted feature map array\n",
    "for i in top_10_indices:\n",
    "\n",
    "    print((inverted_feature_map[i], float(hausa_feature_vector[i])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxuk4VZryE1R"
   },
   "source": [
    "Now, for each language, print the top-10 features. Print the name of each language, and then a list of it's top-10 features on the following line, e.g.\n",
    "\n",
    "```\n",
    "hausa\n",
    "[(\"aaa\", 0.04597442104739769)...]\n",
    "indonesian\n",
    "[(\"aaa\", 0.04597442104739769)...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759511637681,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "flCuKMqLyE1R",
    "output_for": "4.3",
    "tags": [
     "Answer Expected"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hausa\n",
      "[('da ', 0.06451164031068245), (' da', 0.05814918884378874), ('in ', 0.032426575762492936), (' ba', 0.02643611391809732), ('ar ', 0.02555232352139255), (' ya', 0.024015673618085424), (' sh', 0.021499026046531342), ('ai ', 0.02050666010795031), ('ya ', 0.019389629427255823), (' su', 0.018342154705746547)]\n",
      "indonesian\n",
      "[('an ', 0.06799812627407179), (' me', 0.06543762169208904), ('ang', 0.05864670458556179), (' se', 0.03851761535028479), ('ber', 0.0383095340146406), (' ke', 0.037826103731030895), (' be', 0.037697260417012685), ('men', 0.03458735237992753), (' di', 0.03337809762163509), ('ah ', 0.033316062263282056)]\n",
      "manobo\n",
      "[(' to', 0.11172142481570511), ('to ', 0.10867440466425177), (' no', 0.0703878240240312), ('no ', 0.05737575834850775), ('an ', 0.03610684793873696), (' og', 0.03465077972150404), ('n t', 0.03263541784142221), ('ow ', 0.031452540844881166), ('din', 0.029471839883121024), ('on ', 0.02843104526266351)]\n",
      "nahuatl\n",
      "[('tla', 0.06563090226122159), (' tl', 0.06234250856922765), ('en ', 0.04014012547767964), (' in', 0.03989652537102869), ('iva', 0.037600850062865114), ('va ', 0.03745098434168462), ('len', 0.03650553472269728), ('tle', 0.035246157004172045), ('keh', 0.028414809208647425), ('ah ', 0.02811413592790026)]\n",
      "swahili\n",
      "[('wa ', 0.13578784226611998), (' wa', 0.12196677014382869), ('na ', 0.0982997146996272), ('a k', 0.08723643892363422), ('a m', 0.07893224503846277), (' na', 0.0713635597459528), (' ku', 0.06736569148159612), (' ya', 0.06019287441450519), (' kw', 0.06011951676818635), ('ni ', 0.05432704881025502)]\n",
      "tagalog\n",
      "[('ng ', 0.21644808939404278), ('sa ', 0.08822228458053086), (' sa', 0.08387888464030055), ('ang', 0.08170079639784246), (' ng', 0.07466530307810983), (' an', 0.06399350013405733), ('ay ', 0.05738899591491245), ('g m', 0.05332725863917418), ('at ', 0.04886609902535999), (' na', 0.0479801943806834)]\n"
     ]
    }
   ],
   "source": [
    "# the output of this cell will be used for test 4.3\n",
    "# your code here\n",
    "\n",
    "lang_list = sorted(lang_map.keys())\n",
    "\n",
    "\n",
    "for lang in lang_list:\n",
    "    print(lang)\n",
    "    \n",
    "    lang_index = np.argmax(lang_map[lang])\n",
    "\n",
    "    lang_weights = W_inspect[lang_index, 1:]\n",
    "\n",
    "    # print(\"Lang weights\", lang_weights)\n",
    "\n",
    "    top_indices_with_bias = np.argsort(lang_weights[1:])[-10:] # get the indices that would sort the array of feature vectors with bias\n",
    "\n",
    "    # print(\"Top 10 indices with bias\", top_indices_with_bias, \"\\n\")\n",
    "\n",
    "    top_indices_with_bias = top_indices_with_bias[::-1] # flip the indices to turn asxending to become descendng order\n",
    "\n",
    "\n",
    "    top_10_indices = top_indices_with_bias + 1 # add 1 to account for the bias term that was removed\n",
    "\n",
    "    # print(\"Inverted feature map\", inverted_feature_map)\n",
    "    \n",
    "    # get the features corresponding to the top 10 indices using the inverted feature map array\n",
    "    top_10_features = [(inverted_feature_map[i], float(lang_weights[i])) for i in top_10_indices] \n",
    "\n",
    "\n",
    "    print(top_10_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJQuqbexyE1R"
   },
   "source": [
    "Choose one of the languages, and peruse its Wikipedia page or other reliable resources to learn a bit more about the language. Do the top 10 features in that language make sense given what you've learned about the structure of the language? Why or why not? Again, consider reasons stemming both from what you've learned about the language, as well as machine learning and multinomial logistic regression specifically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kN8KW-cJyE1R"
   },
   "source": [
    "### Extra Credit\n",
    "\n",
    "Implement at least one of the experiments you devised to test your hypothesis regarding misclassification of Hausa as Swahili. In order to get credit you must submit not just the code and results, but also clearly describe your hypothesis, the experiment, and why the experiment is suitable to test your hypothesis. Full credit will be given to hypotheses and experiments that are well thought out, explained clearly and convincingly, and backed up with suitable evidence (computed or cited)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1759511930087,
     "user": {
      "displayName": "John Uzodinma",
      "userId": "08674599606987135992"
     },
     "user_tz": -120
    },
    "id": "8CjOAt7tyE1R",
    "outputId": "d82b4f93-e668-4dc4-d303-4745ddd97fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Swahili Trigrams: [('wa ', 864), (' wa', 779), ('a k', 723), ('na ', 676), (' na', 545), ('a m', 534), (' ya', 473), (' ku', 458), ('ya ', 377), (' kw', 367), ('a n', 356), ('ali', 348), ('a w', 336), ('ka ', 326), ('ni ', 323), ('kwa', 310), ('aka', 286), (' ma', 252), (' ka', 241), ('ana', 238)]\n",
      "Top Hausa Trigrams: [('da ', 188), (' da', 178), (' ya', 124), ('in ', 124), ('a k', 117), ('ya ', 112), ('an ', 112), (' ka', 107), ('ka ', 97), (' ba', 95), ('a s', 86), ('na ', 82), (' ma', 80), (' ku', 73), ('ma ', 72), ('ar ', 69), (' wa', 69), ('a y', 68), ('a a', 66), (' ta', 65)]\n",
      "Common Top Trigrams: {' ya', ' ma', 'na ', 'a k', 'ya ', ' ku', ' wa', ' ka', 'ka '}\n"
     ]
    }
   ],
   "source": [
    "# Implement extra credit here.\n",
    "\n",
    "# Hypothesis:\n",
    "# Hausa documents are misclassified as Swahili because they both originated frome arabic script origin and share a significant number of loanwords. These loan seen in common character ngrams. \n",
    "\n",
    "# Experiment:\n",
    "# To test this, I will use trigrams and compare the most frequent trigrams in Hausa and Swahili training data to see how many overlap.\"]\n",
    "\n",
    "# Implementation:\n",
    "def get_top_ngrams(observations, language, n=3, top_k=20):\n",
    "    lang_docs = [doc for lang, doc in observations if lang == language]\n",
    "    all_ngrams = []\n",
    "    for doc in lang_docs:\n",
    "        all_ngrams.extend(extract_ngrams(doc, n))\n",
    "\n",
    "    return Counter(all_ngrams).most_common(top_k)\n",
    "\n",
    "swahili_top_ngrams = get_top_ngrams(train_observations, 'swahili')\n",
    "hausa_top_ngrams = get_top_ngrams(train_observations, 'hausa')\n",
    "\n",
    "# Analysis:\n",
    "# The result shows that hausa and swahili have common character trigrams with the letter 'a' and a space appearing in most of them. This makes the model to assign almost the same weights to these trigrams which then makes the classifier to interpret hausa as swahili and vice versa\n",
    "print(\"Top Swahili Trigrams:\", swahili_top_ngrams)\n",
    "print(\"Top Hausa Trigrams:\", hausa_top_ngrams)\n",
    "\n",
    "\n",
    "common_ngrams = set([ngram for ngram, count in hausa_top_ngrams]) & set([ngram for ngram, count in swahili_top_ngrams])\n",
    "print(\"Common Top Trigrams:\", common_ngrams)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
